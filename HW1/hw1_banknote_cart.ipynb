{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV file and splitting it into feature and label matrices\n",
    "\n",
    "dataset = pd.read_csv('data_banknote_authentication.csv')\n",
    "dataset = dataset.to_numpy()\n",
    "\n",
    "X = dataset[:,0:-1]\n",
    "Y = dataset[:,-1]\n",
    "\n",
    "# Splitting the dataset into training and testing data in the ratio 7:3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "y_train = np.reshape(y_train, (X_train.shape[0],1))\n",
    "X_train = np.append(X_train, y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the features into respective classes (0 and 1)\n",
    "\n",
    "class1 = [] # should have dataset only belonging to inauthentic banknotes\n",
    "class2 = [] # should have dataset only belonging to authentic banknotes\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "  if X_train[i][-1] == 0:\n",
    "      class1.append(X_train[i])\n",
    "  else:\n",
    "      class2.append(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(regions, classes):\n",
    "    \n",
    "    region1 = regions[0]\n",
    "    region2 = regions[1]\n",
    "    n1 = len(region1)\n",
    "    n2 = len(region2)\n",
    "\n",
    "    Q1 = 0\n",
    "    for cls in classes:\n",
    "        count = 0\n",
    "        for pt in region1:\n",
    "            if (pt[-1] == cls):\n",
    "                count += 1\n",
    "        prop = 0\n",
    "        if (n1 != 0):\n",
    "            prop = count/n1\n",
    "        Q1 += prop*(1-prop)\n",
    "\n",
    "    Q2 = 0\n",
    "    for cls in classes:\n",
    "        count = 0\n",
    "        for pt in region2:\n",
    "            if (pt[-1] == cls):\n",
    "                count += 1\n",
    "        prop = 0\n",
    "        if (n2 != 0):\n",
    "            prop = count/n2\n",
    "        Q2 += prop*(1-prop)\n",
    "\n",
    "    Gini = (n1*Q1 + n2*Q2)/(n1+n2)\n",
    "\n",
    "    return Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Create Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an input feature and a input feature value\n",
    "def split_at_root_node(feature_index, value, dataset): \n",
    "\n",
    "    left = []\n",
    "    right = []\n",
    "\n",
    "    for data in dataset:\n",
    "        if (data[feature_index] <= value):\n",
    "            left.append(data)\n",
    "        else:\n",
    "            right.append(data)\n",
    "\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to get best split in a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best split point for a given dataset\n",
    "def get_best_split(dataset):\n",
    "\n",
    "\tfeatures = np.linspace(0,len(dataset[0])-2,num=len(dataset[0])-1,dtype=int) \n",
    "\tbest_index = -1\n",
    "\tbest_value = float('inf')\n",
    "\tbest_gini_score = float('inf')\n",
    "\tbest_regions = []\n",
    "\n",
    "\tfor index in features:\n",
    "\t\tvalues = [row[index] for row in dataset]\n",
    "\t\tset_values = set(values)\n",
    "\t\tunique_values = list(set_values)\n",
    "\t\tunique_values.sort()\n",
    "\t\tfor i in range(len(unique_values)-1):\n",
    "\t\t\tval = (unique_values[i]+unique_values[i+1])/2\n",
    "\t\t\tL, R = split_at_root_node(index, val, dataset)\n",
    "\t\t\tgini = gini_index([L, R], [0, 1])\n",
    "\t\t\t#print('x', index, '<', val, 'gini: ', gini)\n",
    "\t\t\tif (gini < best_gini_score):\n",
    "\t\t\t\tbest_gini_score = gini\n",
    "\t\t\t\tbest_index = index\n",
    "\t\t\t\tbest_value = val\n",
    "\t\t\t\tbest_regions = [L, R]\n",
    "\n",
    "\treturn {'index':best_index, 'value':best_value, 'gini': best_gini_score, 'regions':best_regions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to assign value to a leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a leaf value\n",
    "def leaf_output(region):\n",
    "  outcomes = [row[-1] for row in region]\n",
    "  return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create internal child splits with min_size and max_depth constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates internal child splits for a node or make a leaf node\n",
    "def split(internal_node, max_depth, min_size, depth): \n",
    "  left = internal_node['regions'][0]\n",
    "  right = internal_node['regions'][1]\n",
    "  if not left or not right:\n",
    "    internal_node['left'] = internal_node['right'] = leaf_output(left + right)\n",
    "  elif (depth == max_depth) or (min_size >= (len(left) + len(right))):\n",
    "    internal_node['left'] = leaf_output(left)\n",
    "    internal_node['right'] = leaf_output(right)\n",
    "  else:\n",
    "    left_child = get_best_split(left)\n",
    "    right_child = get_best_split(right)\n",
    "    if left_child['index'] == -1:\n",
    "      internal_node['left'] = left[0][-1]\n",
    "    else:\n",
    "      internal_node['left'] = left_child\n",
    "      split(internal_node['left'], max_depth, min_size, depth+1)\n",
    "    if right_child['index'] == -1:\n",
    "      internal_node['right'] = right[0][-1]\n",
    "    else:\n",
    "      internal_node['right'] = right_child\n",
    "      split(internal_node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to build the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "  root = get_best_split(train)\n",
    "  split(root, max_depth, min_size, 0)\n",
    "  return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to print the built decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "\tif isinstance(node, dict):\n",
    "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "\t\tprint_tree(node['left'], depth+1)\n",
    "\t\tprint_tree(node['right'], depth+1)\n",
    "\telse:\n",
    "\t\tprint('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 < 0.321]\n",
      " [X2 < 7.565]\n",
      "  [X1 < -1.741]\n",
      "   [X2 < 1.772]\n",
      "    [X1 < -5.208]\n",
      "     [1.0]\n",
      "     [X1 < -5.095]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "    [X2 < 1.775]\n",
      "     [0.0]\n",
      "     [X1 < -6.568]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "   [X3 < 6.824]\n",
      "    [X2 < 3.925]\n",
      "     [X3 < 6.216]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "     [X3 < -3.602]\n",
      "      [1.0]\n",
      "      [0.0]\n",
      "    [X2 < -6.808]\n",
      "     [X1 < -1.721]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "     [X1 < -1.715]\n",
      "      [0.0]\n",
      "      [0.0]\n",
      "  [X1 < -3.954]\n",
      "   [X1 < -7.039]\n",
      "    [1.0]\n",
      "    [X1 < -6.998]\n",
      "     [1.0]\n",
      "     [X1 < -6.742]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "   [X1 < -2.728]\n",
      "    [0.0]\n",
      "    [X1 < -2.681]\n",
      "     [0.0]\n",
      "     [X1 < -2.572]\n",
      "      [0.0]\n",
      "      [0.0]\n",
      " [X3 < -4.394]\n",
      "  [X1 < 3.304]\n",
      "   [X1 < 0.403]\n",
      "    [1.0]\n",
      "    [X1 < 0.545]\n",
      "     [1.0]\n",
      "     [X1 < 0.627]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "   [X1 < 4.312]\n",
      "    [0.0]\n",
      "    [0.0]\n",
      "  [X1 < 1.450]\n",
      "   [X3 < -2.243]\n",
      "    [X1 < 0.543]\n",
      "     [1.0]\n",
      "     [X1 < 0.580]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "    [X4 < 0.082]\n",
      "     [X1 < 0.420]\n",
      "      [0.0]\n",
      "      [0.0]\n",
      "     [X3 < 0.324]\n",
      "      [1.0]\n",
      "      [0.0]\n",
      "   [X1 < 2.037]\n",
      "    [X3 < -2.873]\n",
      "     [X1 < 2.024]\n",
      "      [1.0]\n",
      "      [1.0]\n",
      "     [X3 < -2.293]\n",
      "      [0.0]\n",
      "      [0.0]\n",
      "    [X1 < 2.044]\n",
      "     [0.0]\n",
      "     [X1 < 2.053]\n",
      "      [0.0]\n",
      "      [0.0]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(X_train, 5, 10)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to predict using the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set =  99.68717413972888 %\n",
      "Accuracy on testing set =  97.57281553398059 %\n"
     ]
    }
   ],
   "source": [
    "misclassified = 0\n",
    "prediction = []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    output = predict(tree, X_train[i])\n",
    "    prediction.append(output)\n",
    "    if (prediction[i] != y_train[i]):\n",
    "        misclassified += 1\n",
    "\n",
    "print(\"Accuracy on training set = \", 100*(1 - misclassified/y_train.shape[0]), \"%\")\n",
    "\n",
    "\n",
    "misclassified = 0\n",
    "prediction = []\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    output = predict(tree, X_test[i])\n",
    "    prediction.append(output)\n",
    "    if (prediction[i] != y_test[i]):\n",
    "        misclassified += 1\n",
    "\n",
    "print(\"Accuracy on testing set = \", 100*(1 - misclassified/y_test.shape[0]), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
